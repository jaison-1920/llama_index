{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "\n",
        "with open(\"SteveJobsSpeech.pdf\",\"rb\") as input_file:\n",
        "  reader = PyPDF2.PdfReader(input_file)\n",
        "\n",
        "  with open(\"output.txt\",\"w\") as output:\n",
        "    for page_num in range(len(reader.pages)):\n",
        "      page = reader.pages[page_num]\n",
        "      text = page.extract_text()\n",
        "      output.write(text)\n",
        "\n"
      ],
      "metadata": {
        "id": "uUugmPUIIxkZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"output.txt\",'r') as input_file:\n",
        "  text = input_file.read()\n",
        "  print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hetmmkLiKji0",
        "outputId": "30b26266-b94a-4dab-e267-1f938d59ac8d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/301899412\n",
            "Steve Jobs Speech\n",
            "Article  · May 2016\n",
            "CITATIONS\n",
            "0READS\n",
            "158,987\n",
            "1 author:\n",
            "Renisa Me ta\n",
            "Banc o Sant ander\n",
            "4 PUBLICA TIONS    0 CITATIONS    \n",
            "SEE PROFILE\n",
            "All c ontent f ollo wing this p age was uplo aded b y Renisa Me ta on 06 May 2016.\n",
            "The user has r equest ed enhanc ement of the do wnlo aded file.STEVE JOBS,  \n",
            "JUNE 14  2005 , STANFORD  \n",
            " \n",
            "I am honored to be with you today at your commencement from one of  the finest universities in the \n",
            "world. I never graduated from college. Truth be told, this is the closest I've ever gotten to a college  \n",
            "graduation. Today I want to tell you three stories from my life. Tha t's it. No big deal. Just three \n",
            "stories.  \n",
            " \n",
            " \n",
            "The first story is about connecting the dots.  \n",
            " \n",
            "I dropped out of Reed College after the first 6 months, but then stayed around as a drop -in for  \n",
            "anoth er 18 months or so before I really quit. So why did I drop out?  \n",
            " \n",
            "It started before I was born. My biological mother was a young, unwed college graduate student,  \n",
            "and she decided to put me up for adoption. She felt very strongly that I should be adopted by  \n",
            "college graduates, so everything was all set for me to be adopted at birth by a lawyer and his wife.  \n",
            "Except that when I popped out they decided at the last minute that they really wanted a girl. So my  \n",
            "parents, who were on a waiting list, got a call in the mi ddle of the night asking: \"We have an  \n",
            "unexpected baby boy; do you want him?\" They said: \"Of course.\" My biological mother later found  \n",
            "out that my mother had never graduated from college and that my father had never graduated from  \n",
            "high school. She refused t o sign the final adoption papers. She only relented a few months later  \n",
            "when my parents promised that I would someday go to college.  \n",
            " \n",
            "And 17 years later I did go to college. But I naively chose a college that was almost as expensive  \n",
            "as Stanford, and all of m y working -class parents' savings were being spent on my college tuition.  \n",
            "After six months, I couldn't see the value in it. I had no idea what I wanted to do with my life and no  \n",
            "idea how college was going to help me figure it out. And here I was spending al l of the money my  \n",
            "parents had saved their entire life. So I decided to drop out and trust that it would all work out OK.  \n",
            "It was pretty scary at the time, but looking back it was one of the best decisions I ever made. The  \n",
            "minute I dropped out I could stop t aking the required classes that didn't interest me, and begin  \n",
            "dropping in on the ones that looked interesting.  \n",
            " \n",
            "It wasn't all romantic. I didn't have a dorm room, so I slept on the floor in friends' rooms, I returned  \n",
            "coke bottles for the 5¢ deposits to buy food with, and I would walk the 7 miles across town every  \n",
            "Sunday night to get one good meal a week at the Hare Krishna temple. I loved it. And much of  \n",
            "what I stumbled into by following my curiosity and intuition turned out to be priceless later on. Let  \n",
            "me give you one example:  \n",
            " \n",
            "Reed College at that time offered perhaps the best calligraphy instruction in the country.  \n",
            "Throughout the campus every poster, every label on every drawer, was beautifully hand  \n",
            "calligraphed. Because I had dropped out and didn't have to take the normal classes, I decided to  \n",
            "take a calligraphy class to learn how to do this. I learned about serif and san serif typefaces, about  \n",
            "varying the amount of space between different letter com binations, about what makes great  \n",
            "typography great. It was beautiful, historical, artistically subtle in a way that science can't capture,  \n",
            "and I found it fascinating.  \n",
            " \n",
            "None of this had even a hope of any practical application in my life. But ten years later , when we  \n",
            "were designing the first Macintosh computer, it all came back to me. And we designed it all into the  \n",
            "Mac. It was the first computer with beautiful typography. If I had never dropped in on that single  \n",
            "course in college, the Mac would have never ha d multiple typefaces or proportionally spaced fonts.  \n",
            "And since Windows just copied the Mac, its likely that no personal computer would have them. If I  \n",
            "had never dropped out, I would have never dropped in on this calligraphy class, and personal  \n",
            "computers mi ght not have the wonderful typography that they do. Of course it was impossible to  \n",
            "connect the dots looking forward when I was in college. But it was very, very clear looking  \n",
            "backwards ten years later.   \n",
            "Again, you can't connect the dots looking forward; you  can only connect them looking backwards.  \n",
            "So you have to trust that the dots will somehow connect in your future. You have to trust in  \n",
            "something — your gut, destiny, life, karma, whatever. This approach has never let me down, and it  \n",
            "has made all the differ ence in my life.  \n",
            " \n",
            " \n",
            "My second story is about love and loss.  \n",
            " \n",
            "I was lucky — I found what I loved to do early in life. Woz and I started Apple in my parents garage  \n",
            "when I was 20. We worked hard, and in 10 years Apple had grown from just the two of us in a  \n",
            "garage  into a $2 billion company with over 4000 employees. We had just released our finest  \n",
            "creation — the Macintosh — a year earlier, and I had just turned 30. And then I got fired. How can  \n",
            "you get fired from a company you started? Well, as Apple grew we hired s omeone who I thought  \n",
            "was very talented to run the company with me, and for the first year or so things went well. But  \n",
            "then our visions of the future began to diverge and eventually we had a falling out. When we did,  \n",
            "our Board of Directors sided with him. S o at 30 I was out. And very publicly out. What had been the  \n",
            "focus of my entire adult life was gone, and it was devastating.  \n",
            " \n",
            "I really didn't know what to do for a few months. I felt that I had let the previous generation of  \n",
            "entrepreneurs down - that I had d ropped the baton as it was being passed to me. I met with David  \n",
            "Packard and Bob Noyce and tried to apologize for screwing up so badly. I was a very public failure,  \n",
            "and I even thought about running away from the valley. But something slowly began to dawn on  \n",
            "me — I still loved what I did. The turn of events at Apple had not changed that one bit. I had been  \n",
            "rejected, but I was still in love. And so I decided to start over.  \n",
            "I didn't see it then, but it turned out that getting fired from Apple was the best thing  that could have  \n",
            "ever happened to me. The heaviness of being successful was replaced by the lightness of being a  \n",
            "beginner again, less sure about everything. It freed me to enter one of the most creative periods of  \n",
            "my life.  \n",
            " \n",
            "During the next five years, I sta rted a company named NeXT, another company named Pixar, and  \n",
            "fell in love with an amazing woman who would become my wife. Pixar went on to create the worlds  \n",
            "first computer animated feature film, Toy Story, and is now the most successful animation studio in  \n",
            "the world. In a remarkable turn of events, Apple bought NeXT, I returned to Apple, and the  \n",
            "technology we developed at NeXT is at the heart of Apple's current renaissance. And Laurene and  \n",
            "I have a wonderful family together.  \n",
            " \n",
            "I'm pretty sure none of this woul d have happened if I hadn't been fired from Apple. It was awful  \n",
            "tasting medicine, but I guess the patient needed it. Sometimes life hits you in the head with a brick.  \n",
            "Don't lose faith. I'm convinced that the only thing that kept me going was that I loved w hat I did.  \n",
            "You've got to find what you love. And that is as true for your work as it is for your lovers. Your work  \n",
            "is going to fill a large part of your life, and the only way to be truly satisfied is to do what you  \n",
            "believe is great work. And the only way to do great work is to love what you do. If you haven't  \n",
            "found it yet, keep looking. Don't settle. As with all matters of the heart, you'll know when you find it.  \n",
            "And, like any great relationship, it just gets better and better as the years roll on. So keep  looking  \n",
            "until you find it. Don't settle.  \n",
            " \n",
            " \n",
            "My third story is about death.  \n",
            " \n",
            "When I was 17, I read a quote that went something like: \"If you live each day as if it was your last,  \n",
            "someday  you'll most certainly be right \". It made an impression on me, and since then, for the past  \n",
            "33 years, I have looked in the mirror every morning and asked myself: \"If today were the last day of  \n",
            "my life, would I want to do what I am about to do today? \" And whenever the answer has been \"No\"  \n",
            "for too many days in a row, I know I need to change something.  \n",
            " Remembering that I'll be dead soon is the most important tool I've ever encountered to help me  \n",
            "make the big choices in life. Because almost everything — all external expectations, all pride, all  \n",
            "fear of embarrassment or failure - these things just fall away in the face of death, leaving only what  \n",
            "is truly important. Remembering that you are going to die is the best way I know to avoid the trap  \n",
            "of thinking you have something to lose. You are already naked. There is no reason not to follow  \n",
            "your heart.  \n",
            " \n",
            "About a year ago I was diagnosed with cancer. I had a scan at 7:30 in the morning, and it clearly  \n",
            "showed a tumor on my pancreas. I didn't even know what a pancr eas was. The doctors told me  \n",
            "this was almost certainly a type of cancer that is incurable, and that I should expect to live no  \n",
            "longer than three to six months. My doctor advised me to go home and get my affairs in order,  \n",
            "which is doctor's code for prepare to die. It means to try to tell your kids everything you thought  \n",
            "you'd have the next 10 years to tell them in just a few months. It means to make sure everything is  \n",
            "buttoned up so that it will be as easy as possible for your family. It means to say your go odbyes.  \n",
            "I lived with that diagnosis all day. Later that evening I had a biopsy, where they stuck an  \n",
            "endoscope down my throat, through my stomach and into my i ntestines, put a needle into my \n",
            "pancreas and got a few cells from the tumor. I was sedated, but my  wife, who was there, told me  \n",
            "that when they viewed the cells under a microscope the doctors s tarted crying because it turned \n",
            "out to be a very rare form of pancreatic cancer that is curable with surgery. I had the surgery and  \n",
            "I'm fine now.  \n",
            " \n",
            "This was the clo sest I've been to facing death, and I hope its the closest I get for a few more  \n",
            "decades. Having lived through it, I can now say this to you with a bit more certainty than when  \n",
            "death was a useful but purely intellectual concept:  \n",
            " \n",
            "No one wants to die. Even pe ople who want to go to heaven don't want to die to get there. And yet  \n",
            "death is the destination we all share. No one has ever escaped it. And that is as it should be,  \n",
            "because Death is very likely the single best invention of Life. It is Lif e's change agent. It clears out \n",
            "the old to make way for the new. Right now the new is you, but someday not too long from now,  \n",
            "you will gradually become the old and be cleared away. So rry to be so dramatic, but it is quite true.  \n",
            "Your time is limited, so don't waste it living someone else's life. Don't be trapped by dogma — \n",
            "which is living with the results of other people's thinking. Don't let the noise of others' opinions  \n",
            "drown out your  own inner voice. And most important, have the courage to follow your heart and  \n",
            "intuition. They somehow already know what you truly want to become. Everything else is  \n",
            "secondary.  \n",
            " \n",
            "When I was young, there was an amazing publication called The Whole Earth Cata log, which was  \n",
            "one of the bibles of my generation. It was created by a fellow named Stewart Brand not far from  \n",
            "here in Menlo Park, and he brought it to life with his poetic touch. This was in the late 1960's,  \n",
            "before personal computers and desktop publishin g, so it was all m ade with typewriters, scissors, \n",
            "and polaroid cameras. It was sort of like Google in paperback form, 35 years before Google came  \n",
            "along: it was idealistic, and overflowing with neat tools and great notions.  \n",
            " \n",
            "Stewart and his team put out seve ral issues of The Whole Earth Catalog, and then when it had run  \n",
            "its course, they put out a final issue. It was the mid -1970s, and I was your age. On the back cover \n",
            "of their final issue was a photograph of an early morning country road, the kind you might f ind \n",
            "yourself hitchhiking on if you were so adventurous. Beneath it were the words: \"Stay Hungry. Stay  \n",
            "Foolish.\" It was their farewell message as they signed off. Stay Hungry. Stay Foolish. And I have  \n",
            "always wished that for myself. And now, as you graduate to begin anew, I wish that for you.  \n",
            "Stay Hungry. Stay Foolish.  \n",
            " \n",
            "Thank you all very much.  \n",
            " \n",
            "SJ \n",
            "View publication stats\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index llama-index-llms-huggingface llama-index-llms-huggingface-api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDlz_wXZMU7X",
        "outputId": "c2a40139-6e6e-4377-e7ae-2ad03be2dd35"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.11.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting llama-index-llms-huggingface\n",
            "  Downloading llama_index_llms_huggingface-0.3.1-py3-none-any.whl.metadata (789 bytes)\n",
            "Collecting llama-index-llms-huggingface-api\n",
            "  Downloading llama_index_llms_huggingface_api-0.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting llama-index-agent-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.3.0-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-cli<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_cli-0.3.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core==0.11.0.post1 (from llama-index)\n",
            "  Downloading llama_index_core-0.11.0.post1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting llama-index-embeddings-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.2.2-py3-none-any.whl.metadata (686 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
            "  Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting llama-index-llms-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.2.0-py3-none-any.whl.metadata (648 bytes)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.2.0-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting llama-index-readers-file<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.2.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.2.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting nltk>3.8.1 (from llama-index)\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.11.0.post1->llama-index) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama-index) (3.10.5)\n",
            "Collecting dataclasses-json (from llama-index-core==0.11.0.post1->llama-index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.11.0.post1->llama-index)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.11.0.post1->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama-index) (2024.6.1)\n",
            "Collecting httpx (from llama-index-core==0.11.0.post1->llama-index)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama-index) (3.3)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama-index) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama-index) (9.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama-index) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama-index) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core==0.11.0.post1->llama-index)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core==0.11.0.post1->llama-index)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama-index) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama-index) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core==0.11.0.post1->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama-index) (1.16.0)\n",
            "Requirement already satisfied: huggingface-hub<0.24.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (0.23.5)\n",
            "Collecting text-generation<0.8.0,>=0.7.0 (from llama-index-llms-huggingface)\n",
            "  Downloading text_generation-0.7.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (2.3.1+cu121)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.15.4)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (24.1)\n",
            "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.4.0,>=0.3.0->llama-index)\n",
            "  Downloading openai-1.42.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index)\n",
            "  Downloading llama_cloud-0.0.15-py3-none-any.whl.metadata (751 bytes)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.1.4)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (4.12.3)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.2.0->llama-index)\n",
            "  Downloading llama_parse-0.5.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (2024.5.15)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.13.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.19.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.32.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.0.post1->llama-index) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.0.post1->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.0.post1->llama-index) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.0.post1->llama-index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.0.post1->llama-index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.0.post1->llama-index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.0.post1->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (2.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.11.0.post1->llama-index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.11.0.post1->llama-index) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core==0.11.0.post1->llama-index)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.11.0.post1->llama-index) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.11.0.post1->llama-index) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core==0.11.0.post1->llama-index)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.0->llama-index) (1.7.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.0->llama-index)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core==0.11.0.post1->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core==0.11.0.post1->llama-index) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.11.0.post1->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.11.0.post1->llama-index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.11.0.post1->llama-index) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core==0.11.0.post1->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core==0.11.0.post1->llama-index)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core==0.11.0.post1->llama-index) (1.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.16.0)\n",
            "Downloading llama_index-0.11.0-py3-none-any.whl (6.8 kB)\n",
            "Downloading llama_index_core-0.11.0.post1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_huggingface-0.3.1-py3-none-any.whl (11 kB)\n",
            "Downloading llama_index_llms_huggingface_api-0.2.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading llama_index_agent_openai-0.3.0-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.3.0-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_embeddings_openai-0.2.2-py3-none-any.whl (6.3 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.3.0-py3-none-any.whl (9.5 kB)\n",
            "Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.2.0-py3-none-any.whl (12 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.2.0-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.2.0-py3-none-any.whl (38 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.2.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading text_generation-0.7.0-py3-none-any.whl (12 kB)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading llama_cloud-0.0.15-py3-none-any.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.2/180.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.5.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading openai-1.42.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.9/362.9 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: striprtf, dirtyjson, tenacity, pypdf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nltk, mypy-extensions, marshmallow, jiter, h11, deprecated, typing-inspect, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, httpcore, text-generation, nvidia-cusolver-cu12, httpx, dataclasses-json, openai, llama-index-core, llama-cloud, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-llms-huggingface-api, llama-index-legacy, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-llms-huggingface, llama-index-question-gen-openai, llama-index\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "Successfully installed dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 llama-cloud-0.0.15 llama-index-0.11.0 llama-index-agent-openai-0.3.0 llama-index-cli-0.3.0 llama-index-core-0.11.0.post1 llama-index-embeddings-openai-0.2.2 llama-index-indices-managed-llama-cloud-0.3.0 llama-index-legacy-0.9.48.post3 llama-index-llms-huggingface-0.3.1 llama-index-llms-huggingface-api-0.2.0 llama-index-llms-openai-0.2.0 llama-index-multi-modal-llms-openai-0.2.0 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-file-0.2.0 llama-index-readers-llama-parse-0.2.0 llama-parse-0.5.0 marshmallow-3.22.0 mypy-extensions-1.0.0 nltk-3.9.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 openai-1.42.0 pypdf-4.3.1 striprtf-0.0.26 tenacity-8.5.0 text-generation-0.7.0 tiktoken-0.7.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "from huggingface_hub import login"
      ],
      "metadata": {
        "id": "BEeYl8-pzrRX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HF_TOKEN = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "651CXr4w0ObP",
        "outputId": "a418d468-e30f-47a1-fdc7-5f741dbe0cf6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "login(token=HF_TOKEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHWxEQZh0SjN",
        "outputId": "3d4adee0-32f5-422e-99ac-6cdaa24949b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"SteveJobsSpeech.txt\",\"r\",encoding=\"utf-8\") as file:\n",
        "  text = file.read()"
      ],
      "metadata": {
        "id": "n4oC_8m90kyj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qBeqA9fQ01_A",
        "outputId": "ff12a091-f2ce-42de-e8af-32527401ef30"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/301899412\\nSteve Jobs Speech\\nArticle  · May 2016\\nCITATIONS\\n0READS\\n158,987\\n1 author:\\nRenisa Me ta\\nBanc o Sant ander\\n4 PUBLICA TIONS \\xa0\\xa0\\xa00 CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll c ontent f ollo wing this p age was uplo aded b y Renisa Me ta on 06 May 2016.\\nThe user has r equest ed enhanc ement of the do wnlo aded file.STEVE JOBS,  \\nJUNE 14  2005 , STANFORD  \\n \\nI am honored to be with you today at your commencement from one of  the finest universities in the \\nworld. I never graduated from college. Truth be told, this is the closest I\\'ve ever gotten to a college  \\ngraduation. Today I want to tell you three stories from my life. Tha t\\'s it. No big deal. Just three \\nstories.  \\n \\n \\nThe first story is about connecting the dots.  \\n \\nI dropped out of Reed College after the first 6 months, but then stayed around as a drop -in for  \\nanoth er 18 months or so before I really quit. So why did I drop out?  \\n \\nIt started before I was born. My biological mother was a young, unwed college graduate student,  \\nand she decided to put me up for adoption. She felt very strongly that I should be adopted by  \\ncollege graduates, so everything was all set for me to be adopted at birth by a lawyer and his wife.  \\nExcept that when I popped out they decided at the last minute that they really wanted a girl. So my  \\nparents, who were on a waiting list, got a call in the mi ddle of the night asking: \"We have an  \\nunexpected baby boy; do you want him?\" They said: \"Of course.\" My biological mother later found  \\nout that my mother had never graduated from college and that my father had never graduated from  \\nhigh school. She refused t o sign the final adoption papers. She only relented a few months later  \\nwhen my parents promised that I would someday go to college.  \\n \\nAnd 17 years later I did go to college. But I naively chose a college that was almost as expensive  \\nas Stanford, and all of m y working -class parents\\' savings were being spent on my college tuition.  \\nAfter six months, I couldn\\'t see the value in it. I had no idea what I wanted to do with my life and no  \\nidea how college was going to help me figure it out. And here I was spending al l of the money my  \\nparents had saved their entire life. So I decided to drop out and trust that it would all work out OK.  \\nIt was pretty scary at the time, but looking back it was one of the best decisions I ever made. The  \\nminute I dropped out I could stop t aking the required classes that didn\\'t interest me, and begin  \\ndropping in on the ones that looked interesting.  \\n \\nIt wasn\\'t all romantic. I didn\\'t have a dorm room, so I slept on the floor in friends\\' rooms, I returned  \\ncoke bottles for the 5¢ deposits to buy food with, and I would walk the 7 miles across town every  \\nSunday night to get one good meal a week at the Hare Krishna temple. I loved it. And much of  \\nwhat I stumbled into by following my curiosity and intuition turned out to be priceless later on. Let  \\nme give you one example:  \\n \\nReed College at that time offered perhaps the best calligraphy instruction in the country.  \\nThroughout the campus every poster, every label on every drawer, was beautifully hand  \\ncalligraphed. Because I had dropped out and didn\\'t have to take the normal classes, I decided to  \\ntake a calligraphy class to learn how to do this. I learned about serif and san serif typefaces, about  \\nvarying the amount of space between different letter com binations, about what makes great  \\ntypography great. It was beautiful, historical, artistically subtle in a way that science can\\'t capture,  \\nand I found it fascinating.  \\n \\nNone of this had even a hope of any practical application in my life. But ten years later , when we  \\nwere designing the first Macintosh computer, it all came back to me. And we designed it all into the  \\nMac. It was the first computer with beautiful typography. If I had never dropped in on that single  \\ncourse in college, the Mac would have never ha d multiple typefaces or proportionally spaced fonts.  \\nAnd since Windows just copied the Mac, its likely that no personal computer would have them. If I  \\nhad never dropped out, I would have never dropped in on this calligraphy class, and personal  \\ncomputers mi ght not have the wonderful typography that they do. Of course it was impossible to  \\nconnect the dots looking forward when I was in college. But it was very, very clear looking  \\nbackwards ten years later.   \\nAgain, you can\\'t connect the dots looking forward; you  can only connect them looking backwards.  \\nSo you have to trust that the dots will somehow connect in your future. You have to trust in  \\nsomething — your gut, destiny, life, karma, whatever. This approach has never let me down, and it  \\nhas made all the differ ence in my life.  \\n \\n \\nMy second story is about love and loss.  \\n \\nI was lucky — I found what I loved to do early in life. Woz and I started Apple in my parents garage  \\nwhen I was 20. We worked hard, and in 10 years Apple had grown from just the two of us in a  \\ngarage  into a $2 billion company with over 4000 employees. We had just released our finest  \\ncreation — the Macintosh — a year earlier, and I had just turned 30. And then I got fired. How can  \\nyou get fired from a company you started? Well, as Apple grew we hired s omeone who I thought  \\nwas very talented to run the company with me, and for the first year or so things went well. But  \\nthen our visions of the future began to diverge and eventually we had a falling out. When we did,  \\nour Board of Directors sided with him. S o at 30 I was out. And very publicly out. What had been the  \\nfocus of my entire adult life was gone, and it was devastating.  \\n \\nI really didn\\'t know what to do for a few months. I felt that I had let the previous generation of  \\nentrepreneurs down - that I had d ropped the baton as it was being passed to me. I met with David  \\nPackard and Bob Noyce and tried to apologize for screwing up so badly. I was a very public failure,  \\nand I even thought about running away from the valley. But something slowly began to dawn on  \\nme — I still loved what I did. The turn of events at Apple had not changed that one bit. I had been  \\nrejected, but I was still in love. And so I decided to start over.  \\nI didn\\'t see it then, but it turned out that getting fired from Apple was the best thing  that could have  \\never happened to me. The heaviness of being successful was replaced by the lightness of being a  \\nbeginner again, less sure about everything. It freed me to enter one of the most creative periods of  \\nmy life.  \\n \\nDuring the next five years, I sta rted a company named NeXT, another company named Pixar, and  \\nfell in love with an amazing woman who would become my wife. Pixar went on to create the worlds  \\nfirst computer animated feature film, Toy Story, and is now the most successful animation studio in  \\nthe world. In a remarkable turn of events, Apple bought NeXT, I returned to Apple, and the  \\ntechnology we developed at NeXT is at the heart of Apple\\'s current renaissance. And Laurene and  \\nI have a wonderful family together.  \\n \\nI\\'m pretty sure none of this woul d have happened if I hadn\\'t been fired from Apple. It was awful  \\ntasting medicine, but I guess the patient needed it. Sometimes life hits you in the head with a brick.  \\nDon\\'t lose faith. I\\'m convinced that the only thing that kept me going was that I loved w hat I did.  \\nYou\\'ve got to find what you love. And that is as true for your work as it is for your lovers. Your work  \\nis going to fill a large part of your life, and the only way to be truly satisfied is to do what you  \\nbelieve is great work. And the only way to do great work is to love what you do. If you haven\\'t  \\nfound it yet, keep looking. Don\\'t settle. As with all matters of the heart, you\\'ll know when you find it.  \\nAnd, like any great relationship, it just gets better and better as the years roll on. So keep  looking  \\nuntil you find it. Don\\'t settle.  \\n \\n \\nMy third story is about death.  \\n \\nWhen I was 17, I read a quote that went something like: \"If you live each day as if it was your last,  \\nsomeday  you\\'ll most certainly be right \". It made an impression on me, and since then, for the past  \\n33 years, I have looked in the mirror every morning and asked myself: \"If today were the last day of  \\nmy life, would I want to do what I am about to do today? \" And whenever the answer has been \"No\"  \\nfor too many days in a row, I know I need to change something.  \\n Remembering that I\\'ll be dead soon is the most important tool I\\'ve ever encountered to help me  \\nmake the big choices in life. Because almost everything — all external expectations, all pride, all  \\nfear of embarrassment or failure - these things just fall away in the face of death, leaving only what  \\nis truly important. Remembering that you are going to die is the best way I know to avoid the trap  \\nof thinking you have something to lose. You are already naked. There is no reason not to follow  \\nyour heart.  \\n \\nAbout a year ago I was diagnosed with cancer. I had a scan at 7:30 in the morning, and it clearly  \\nshowed a tumor on my pancreas. I didn\\'t even know what a pancr eas was. The doctors told me  \\nthis was almost certainly a type of cancer that is incurable, and that I should expect to live no  \\nlonger than three to six months. My doctor advised me to go home and get my affairs in order,  \\nwhich is doctor\\'s code for prepare to die. It means to try to tell your kids everything you thought  \\nyou\\'d have the next 10 years to tell them in just a few months. It means to make sure everything is  \\nbuttoned up so that it will be as easy as possible for your family. It means to say your go odbyes.  \\nI lived with that diagnosis all day. Later that evening I had a biopsy, where they stuck an  \\nendoscope down my throat, through my stomach and into my i ntestines, put a needle into my \\npancreas and got a few cells from the tumor. I was sedated, but my  wife, who was there, told me  \\nthat when they viewed the cells under a microscope the doctors s tarted crying because it turned \\nout to be a very rare form of pancreatic cancer that is curable with surgery. I had the surgery and  \\nI\\'m fine now.  \\n \\nThis was the clo sest I\\'ve been to facing death, and I hope its the closest I get for a few more  \\ndecades. Having lived through it, I can now say this to you with a bit more certainty than when  \\ndeath was a useful but purely intellectual concept:  \\n \\nNo one wants to die. Even pe ople who want to go to heaven don\\'t want to die to get there. And yet  \\ndeath is the destination we all share. No one has ever escaped it. And that is as it should be,  \\nbecause Death is very likely the single best invention of Life. It is Lif e\\'s change agent. It clears out \\nthe old to make way for the new. Right now the new is you, but someday not too long from now,  \\nyou will gradually become the old and be cleared away. So rry to be so dramatic, but it is quite true.  \\nYour time is limited, so don\\'t waste it living someone else\\'s life. Don\\'t be trapped by dogma — \\nwhich is living with the results of other people\\'s thinking. Don\\'t let the noise of others\\' opinions  \\ndrown out your  own inner voice. And most important, have the courage to follow your heart and  \\nintuition. They somehow already know what you truly want to become. Everything else is  \\nsecondary.  \\n \\nWhen I was young, there was an amazing publication called The Whole Earth Cata log, which was  \\none of the bibles of my generation. It was created by a fellow named Stewart Brand not far from  \\nhere in Menlo Park, and he brought it to life with his poetic touch. This was in the late 1960\\'s,  \\nbefore personal computers and desktop publishin g, so it was all m ade with typewriters, scissors, \\nand polaroid cameras. It was sort of like Google in paperback form, 35 years before Google came  \\nalong: it was idealistic, and overflowing with neat tools and great notions.  \\n \\nStewart and his team put out seve ral issues of The Whole Earth Catalog, and then when it had run  \\nits course, they put out a final issue. It was the mid -1970s, and I was your age. On the back cover \\nof their final issue was a photograph of an early morning country road, the kind you might f ind \\nyourself hitchhiking on if you were so adventurous. Beneath it were the words: \"Stay Hungry. Stay  \\nFoolish.\" It was their farewell message as they signed off. Stay Hungry. Stay Foolish. And I have  \\nalways wished that for myself. And now, as you graduate to begin anew, I wish that for you.  \\nStay Hungry. Stay Foolish.  \\n \\nThank you all very much.  \\n \\nSJ \\nView publication stats'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.huggingface import HuggingFaceInferenceAPI"
      ],
      "metadata": {
        "id": "bZOxhCkP03js"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceInferenceAPI(model_name='mistralai/Mixtral-8x7B-Instruct-v0.1',token=HF_TOKEN)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AdQ0kZg1EoW",
        "outputId": "f1ac3fc1-0276-4c1e-d7da-b537255277d0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-1b97be298f3a>:1: DeprecationWarning: Call to deprecated class HuggingFaceInferenceAPI. (Deprecated in favor of `HuggingFaceInferenceAPI` from `llama-index-llms-huggingface-api` which should be used instead.)\n",
            "  llm = HuggingFaceInferenceAPI(model_name='mistralai/Mixtral-8x7B-Instruct-v0.1',token=HF_TOKEN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import PromptTemplate\n",
        "template = (\n",
        "    \"We have provided context information below. \\n\"\n",
        "    \"---------------------\\n\"\n",
        "    \"{context_str}\"\n",
        "    \"\\n---------------------\\n\"\n",
        "    \"Given this information, please answer the question: {query_str}\\n\"\n",
        ")"
      ],
      "metadata": {
        "id": "g1BFrAZw1eD0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_template = PromptTemplate(template)\n",
        "question = \"What is this speech about?\"\n",
        "prompt = qa_template.format(context_str=text,query_str=question)\n",
        "response = llm.complete(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-2D7WUH2EH6",
        "outputId": "f14a3c43-d49c-45f1-f356-6483f2a96cd3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This speech is about Steve Jobs' life and the lessons he learned from his experiences. He tells three stories: one about connecting the dots, one about love and loss, and one about death. He encourages the graduates to trust in something, to find what they love and to not settle, and to stay hungry and stay foolish.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"what did steve jobs said about his friend?\"\n",
        "prompt = qa_template.format(context_str=text,query_str=question)\n",
        "response = llm.complete(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_hemg7320kS",
        "outputId": "26d9fe68-6de9-4982-8f69-68ea1db416b0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steve Jobs said that his friend, Steve Wozniak, was very talented and that they started Apple together in Jobs' parents' garage when Jobs was 20.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is Steve Jobs's second story about?\"\n",
        "prompt = qa_template.format(context_str=text,query_str=question)\n",
        "response = llm.complete(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhwxmDEm4CwM",
        "outputId": "b46f7044-48da-4aff-c4d1-ad0ef214349f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steve Jobs's second story is about love and loss. He was fired from Apple, the company he co-founded, and felt that he had let down the previous generation of entrepreneurs. However, getting fired allowed him to start new companies and meet his future wife. He believes that getting fired was the best thing that could have happened to him.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Give the summary of speech in 200 words\"\n",
        "prompt = qa_template.format(context_str=text,query_str=question)\n",
        "response = llm.complete(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V_Q_tXq4MaY",
        "outputId": "d9ab0e26-d45e-4dfe-d54c-9cdeff40fcb1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steve Jobs, the co-founder of Apple Inc., delivered a speech at Stanford University's commencement ceremony on June 14, 2005. In his speech, Jobs shared three stories from his life that he believed were significant in shaping his career and personal life.\n",
            "The first story was about connecting the dots. Jobs dropped out of Reed College after six months but continued to attend classes that interested him. He took a calligraphy class that he found fascinating, even though it had no practical application at the time. Ten years later, when Apple was designing the first Macintosh computer, Jobs applied the knowledge he gained from the calligraphy class to create beautiful typography, which set the Macintosh apart from other personal computers. Jobs emphasized the importance of trusting one's intuition and following one's curiosity, even if it doesn't seem to make sense at the time.\n",
            "The second story was about love and loss. Jobs was fired from Apple, the company he co-founded, at the age of 30. He felt devastated and lost, but the experience led him to start two new companies, NeXT and Pixar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ClxD4JRw4XSn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}